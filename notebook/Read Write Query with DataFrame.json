{
	"name": "Read Write Query with DataFrame",
	"properties": {
		"description": "How to read, write and query from DataFram within Spark..",
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "SampleSpark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "d42a2920-9e79-4c79-b97e-910899749c1c"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/2a17af02-3f40-4333-87d0-61b9da658777/resourceGroups/databricks-learning-paths/providers/Microsoft.Synapse/workspaces/databricks-synapse/bigDataPools/SampleSpark",
				"name": "SampleSpark",
				"type": "Spark",
				"endpoint": "https://databricks-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SampleSpark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 8,
				"memory": 56,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"# INTRODUCTION BASIC COMMANDS\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Magic Commands\r\n",
					"# MAGIC * Magic Commands are specific to the Databricks notebooks\r\n",
					"# MAGIC * They are very similar to Magic Commands found in comparable notebook products\r\n",
					"# MAGIC * These are built-in commands that do not apply to the notebook's default language\r\n",
					"# MAGIC * A single percent (%) symbol at the start of a cell identifies a Magic Commands\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ### Magic Command: &percnt;sh\r\n",
					"# MAGIC For example, **&percnt;sh** allows us to execute shell commands on the driver\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %sh ps | grep 'java'\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ### Magic Command: Other Languages\r\n",
					"# MAGIC Additional Magic Commands allow for the execution of code in languages other than the notebook's default:\r\n",
					"# MAGIC * **&percnt;python**\r\n",
					"# MAGIC * **&percnt;scala**\r\n",
					"# MAGIC * **&percnt;sql**\r\n",
					"# MAGIC * **&percnt;r**\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %scala\r\n",
					"# MAGIC \r\n",
					"# MAGIC println(\"Hello Scala!\")\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %python\r\n",
					"# MAGIC \r\n",
					"# MAGIC print(\"Hello Python!\")\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %r\r\n",
					"# MAGIC \r\n",
					"# MAGIC print(\"Hello R!\", quote=FALSE)\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %sql\r\n",
					"# MAGIC \r\n",
					"# MAGIC select \"Hello SQL!\"\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ### Magic Command: &percnt;run\r\n",
					"# MAGIC * You can run a notebook from another notebook by using the Magic Command **%run**\r\n",
					"# MAGIC * All variables & functions defined in that other notebook will become available in your current notebook\r\n",
					"# MAGIC \r\n",
					"# MAGIC For example, The following cell should fail to execute because the variable `username` has not yet been declared:\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"print(\"username: \" + username)\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC But we can declare it and a handful of other variables and functions buy running this cell:\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %run \"./Includes/Classroom-Setup\"\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC In this case, the notebook `Classroom Setup` declares the following:\r\n",
					"# MAGIC   * The variable `username`\r\n",
					"# MAGIC   * The variable `userhome`\r\n",
					"# MAGIC   * The function `assertSparkVersion(..)`\r\n",
					"# MAGIC   * And others...\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"print(\"username: \" + username)\r\n",
					"print(\"userhome: \" + userhome)\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC We will use those variables and functions throughout this class.\r\n",
					"# MAGIC \r\n",
					"# MAGIC One of the other things `Classroom Setup` does for us is to mount all the datasets needed for this class into the Databricks File System.\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Databricks File System - DBFS\r\n",
					"# MAGIC * DBFS is a layer over a cloud-based object store\r\n",
					"# MAGIC * Files in DBFS are persisted to the object store\r\n",
					"# MAGIC * The lifetime of files in the DBFS are **NOT** tied to the lifetime of our cluster\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ### Mounting Data into DBFS\r\n",
					"# MAGIC * Mounting other object stores into DBFS gives Databricks users access via the file system\r\n",
					"# MAGIC * This is just one of many techniques for pulling data into Spark\r\n",
					"# MAGIC * The datasets needed for this class have already been mounted for us with the call to `%run \"../Includes/Classroom Setup\"`\r\n",
					"# MAGIC * We will confirm that in just a few minutes\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC \r\n",
					"# MAGIC See also <a href=\"https://docs.azuredatabricks.net/user-guide/dbfs-databricks-file-system.html\" target=\"_blank\">Databricks File System - DBFS</a>.\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ### Databricks Utilities - dbutils\r\n",
					"# MAGIC * You can access the DBFS through the Databricks Utilities class (and other file IO routines).\r\n",
					"# MAGIC * An instance of DBUtils is already declared for us as `dbutils`.\r\n",
					"# MAGIC * For in-notebook documentation on DBUtils you can execute the command `dbutils.help()`.\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC \r\n",
					"# MAGIC See also <a href=\"https://docs.azuredatabricks.net/user-guide/dbutils.html\" target=\"_blank\">Databricks Utilities - dbutils</a>\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"dbutils.help()\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC Additional help is available for each sub-utility:\r\n",
					"# MAGIC * `dbutils.fs.help()`\r\n",
					"# MAGIC * `dbutils.meta.help()`\r\n",
					"# MAGIC * `dbutils.notebook.help()`\r\n",
					"# MAGIC * `dbutils.widgets.help()`\r\n",
					"# MAGIC \r\n",
					"# MAGIC Let's take a look at the file system utilities, `dbutils.fs`\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"dbutils.fs.help()\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ### dbutils.fs.mounts()\r\n",
					"# MAGIC * As previously mentioned, all our datasets should already be mounted\r\n",
					"# MAGIC * We can use `dbutils.fs.mounts()` to verify that assertion\r\n",
					"# MAGIC * This method returns a collection of `MountInfo` objects, one for each mount\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"mounts = dbutils.fs.mounts()\r\n",
					"\r\n",
					"for mount in mounts:\r\n",
					"  print(mount.mountPoint + \" >> \" + mount.source)\r\n",
					"\r\n",
					"print(\"-\"*80)\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ### dbutils.fs.ls(..)\r\n",
					"# MAGIC * And now we can use `dbutils.fs.ls(..)` to view the contents of that mount\r\n",
					"# MAGIC * This method returns a collection of `FileInfo` objects, one for each item in the specified directory\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC \r\n",
					"# MAGIC See also <a href=\"https://docs.azuredatabricks.net/api/latest/dbfs.html#dbfsfileinfo\" target=\"_blank\">FileInfo</a>\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"files = dbutils.fs.ls(\"/mnt/training/\")\r\n",
					"\r\n",
					"for fileInfo in files:\r\n",
					"  print(fileInfo.path)\r\n",
					"\r\n",
					"print(\"-\"*80)\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ### display(..)\r\n",
					"# MAGIC \r\n",
					"# MAGIC Besides printing each item returned from `dbutils.fs.ls(..)` we can also pass that collection to another Databricks specific command called `display(..)`.\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"files = dbutils.fs.ls(\"/mnt/training/\")\r\n",
					"\r\n",
					"display(files)\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC The `display(..)` command is overloaded with a lot of other capabilities:\r\n",
					"# MAGIC * Presents up to 1000 records.\r\n",
					"# MAGIC * Exporting data as CSV.\r\n",
					"# MAGIC * Rendering a multitude of different graphs.\r\n",
					"# MAGIC * Rendering geo-located data on a world map.\r\n",
					"# MAGIC \r\n",
					"# MAGIC And as we will see later, it is also an excellent tool for previewing our data in a notebook.\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC ### Magic Command: &percnt;fs\r\n",
					"# MAGIC \r\n",
					"# MAGIC There is at least one more trick for looking at the DBFS.\r\n",
					"# MAGIC \r\n",
					"# MAGIC It is a wrapper around `dbutils.fs` and it is the Magic Command known as **&percnt;fs**.\r\n",
					"# MAGIC \r\n",
					"# MAGIC The following call is equivalent to the previous call, `display( dbutils.fs.ls(\"/mnt/training\") )` - there is no real difference between the two.\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %fs ls /mnt/training\r\n",
					"\r\n",
					"# COMMAND ----------\r\n",
					"\r\n",
					"# MAGIC %md\r\n",
					"# MAGIC \r\n",
					"# MAGIC ##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Learning More\r\n",
					"# MAGIC \r\n",
					"# MAGIC We like to encourage you to explore the documentation to learn more about the various features of the Databricks platform and notebooks.\r\n",
					"# MAGIC * <a href=\"https://docs.azuredatabricks.net/user-guide/index.html\" target=\"_blank\">User Guide</a>\r\n",
					"# MAGIC * <a href=\"https://docs.databricks.com/user-guide/getting-started.html\" target=\"_blank\">Getting Started with Databricks</a>\r\n",
					"# MAGIC * <a href=\"https://docs.azuredatabricks.net/user-guide/notebooks/index.html\" target=\"_blank\">User Guide / Notebooks</a>\r\n",
					"# MAGIC * <a href=\"https://docs.databricks.com/user-guide/notebooks/index.html#importing-notebooks\" target=\"_blank\">Importing notebooks - Supported Formats</a>\r\n",
					"# MAGIC * <a href=\"https://docs.azuredatabricks.net/administration-guide/index.html\" target=\"_blank\">Administration Guide</a>\r\n",
					"# MAGIC * <a href=\"https://docs.databricks.com/user-guide/clusters/index.html\" target=\"_blank\">Cluster Configuration</a>\r\n",
					"# MAGIC * <a href=\"https://docs.azuredatabricks.net/api/index.html\" target=\"_blank\">REST API</a>\r\n",
					"# MAGIC * <a href=\"https://docs.azuredatabricks.net/release-notes/index.html\" target=\"_blank\">Release Notes</a>\r\n",
					"# MAGIC * <a href=\"https://docs.azuredatabricks.net\" target=\"_blank\">And much more!</a>"
				],
				"execution_count": null
			}
		]
	}
}